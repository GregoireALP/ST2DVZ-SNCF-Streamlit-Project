import streamlit as st
import pandas as pd
from io import StringIO
import re

st.set_page_config(page_title="Data Cleaning", layout="wide")
st.title("üßπ Data Cleaning & Preparation")

st.markdown("""
In this section, we explain **how we cleaned the raw SNCF dataset** to keep only valid rows.
We focus on:
- Removing comment lines
- Keeping only rows starting with a valid date (YYYY-MM)
- Ensuring each row has the correct number of columns
""")

# -----------------------------
# Step 0: Show sample of raw dataset
# -----------------------------
st.header("Step 0: Sample of the raw dataset")

sample_raw = """# This is a comment
Date;Service;Gare de d√©part;Gare d'arriv√©e;Dur√©e moyenne du trajet;Nombre de circulations pr√©vues
2018-01;TGV INOUI;Paris;Lyon;120;50
Comment line inside file
2018-02;TGV INOUI;Paris;Marseille;180;45
"""

st.markdown("Here is an example of the raw data containing comment lines:")
st.code(sample_raw, language="csv")

# -----------------------------
# Step 1: Explain cleaning logic
# -----------------------------
st.header("Step 1: Cleaning logic applied")

st.markdown("""
1Ô∏è‚É£ **Keep the header** (first line) to preserve column names.  
2Ô∏è‚É£ **Filter lines starting with a valid date** in the format `YYYY-MM`.  
3Ô∏è‚É£ **Count the number of columns** and keep only rows matching the header.  
4Ô∏è‚É£ **Load the cleaned lines into pandas** for further analysis.
""")

st.code("""
import re
from io import StringIO
import pandas as pd

pattern = re.compile(r"^20\\d{2}-\\d{2}")
clean_lines = []
expected_cols = None

with open("data.csv", "r", encoding="utf-8") as f:
    lines = f.readlines()

# Keep header
header = lines[0]
clean_lines.append(header)

# Filter valid rows
for line in lines[1:]:
    if pattern.match(line.strip()):
        n_cols = line.count(";") + 1
        if expected_cols is None:
            expected_cols = header.count(";") + 1
        if n_cols == expected_cols:
            clean_lines.append(line)

# Load into pandas
df = pd.read_csv(StringIO("".join(clean_lines)), sep=";")
print(f"{len(df)} valid rows loaded.")
df.info()
""", language="python")
# -----------------------------
# Step 2: Convert data types
# -----------------------------
st.header("Step 2: Convert data types")
st.markdown("To make it easier to manipulate the data, particularly the dates, we need to convert the dates in the dataset to the correct Python format. We clean the dataset further by removing unnecessary columns and filtering out invalid values.")
st.code("""
    # Drop unnecessary comment columns
    df = df.drop(columns=['Commentaire annulations', 'Commentaire retards au d√©part'])
    
    # Convert 'Date' column to datetime
    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m')
    df.info()        
            
    num_cols = df.select_dtypes(include=['int64', 'float64']).columns

    # We only keep the data greater than 0, values less than 0 are not valid
    df_clean = df[(df[num_cols] >= 0).all(axis=1)]
    df = df_clean
""", language="python")
# -----------------------------
# Step 3: Show cleaned dataset info
# -----------------------------
st.header("Step 3: Cleaned dataset overview")

st.markdown("After cleaning, we have **10,335 valid rows** and the following columns:")

columns_overview = [
    "Date", "Service", "Gare de d√©part", "Gare d'arriv√©e",
    "Dur√©e moyenne du trajet", "Nombre de circulations pr√©vues",
    "Nombre de trains annul√©s", "Nombre de trains en retard au d√©part",
    "Retard moyen des trains en retard au d√©part", 
    "Retard moyen de tous les trains au d√©part",
    "Nombre de trains en retard √† l'arriv√©e",
    "Retard moyen des trains en retard √† l'arriv√©e",
    "Retard moyen de tous les trains √† l'arriv√©e",
    "Prct retard pour causes externes", 
    "Prct retard pour cause infrastructure",
    "Prct retard pour cause gestion trafic",
    "Prct retard pour cause mat√©riel roulant",
    "Prct retard pour cause gestion en gare et r√©utilisation de mat√©riel",
    "Prct retard pour cause prise en compte voyageurs"
]

st.write(columns_overview)

# -----------------------------
# Step 4: Show cleaned dataset sample
# -----------------------------
st.header("Step 4: Sample of cleaned dataset")

# Example cleaned DataFrame for demonstration
cleaned_df = pd.DataFrame({
    "Date": ["2018-01", "2018-01", "2018-02"],
    "Service": ["TGV INOUI", "TGV INOUI", "TGV INOUI"],
    "Gare de d√©part": ["Paris", "Paris", "Paris"],
    "Gare d'arriv√©e": ["Lyon", "Marseille", "Lyon"],
    "Dur√©e moyenne du trajet": [120, 180, 125],
    "Nombre de circulations pr√©vues": [50, 45, 48],
    "Nombre de trains en retard au d√©part": [5, 0, 10],
    "Retard moyen des trains en retard au d√©part": [5.0, 0.0, 10.0],
    "Retard moyen de tous les trains au d√©part": [0.5, 0.0, 2.1]
})
st.warning("‚ö†Ô∏è Note: The actual dataset is large, so we are showing a simplified example here.")
st.dataframe(cleaned_df)
st.markdown("‚úÖ Now the dataset is ready for further **analysis and visualization**.")
